This is John's personal developer notes for the CDA1 project.  Probably pretty boring reading
for anyone not intently helping out.

8/21/23

* Project setup & Github repo creation.
* Completed first version of rqmts spec.

8/22/23

* Got legacy cda0 code running after breaking up all the classes in the main environment file
  so they are now in their own files.

8/23/23

* Rewrote the Roadway class to represent the new road geometry.

8/24/23

* Fixed some things in inference prgm and got it to display the new roadway.

8/27/23

* Began revamping the environment model to be more generalized with roadway definition and vehicle population.

8/28-30/23

* Continued building new environment model.

8/31/23

* Built env model to the point that it executes one iteration in inference (prior to checkpoint loading).

9/1/23

* Tried running inference with the final cda0 checkpoint file. It couldn't load because it was looking for
  the old class structure (simple_highway_ramp_wrapper), which is apparently baked into the checkpoint.

* Tried running the tune program - had to make several tweaks & fixes.
	* Got it running in the tuner.  Now to put in some real logic to get the NN to start learning.

9/2/23

* Updated inference prgm to work with the new vehicle structure and with or without a checkpoint (moving
  neighbor vehicles only).

9/3/23

* Fixed problems contributing to graphical display of vehicle locations.
* Ran inference on scenarios 90-95 with Bot1a controller to confirm geometry & speed limits all work.
* Developed & tested Bot1b controller to give offset to speed limit. 
* Ran a sample training job - everything looks nominal.  Ready to build the real learning controller.

9/4/23

* Wrote the Bridgit vehicle model with its huge observation vector encoding. Still need to test it.

9/5/23

* Wrote testing program for BrigitModel and ran them test suite. Found & fixed several defects.
* Tried running a training session, but got exception - too tired to investigate.

9/6/23

* Debugged problems with training. Found & fixed 2 defects.

9/7/23

* Started a training run to verify training will work.
	* Training hangs after 0-2 iterations. Log advances every 5 sec with no changes to the
	  info shown, and no print stmts from any of my code (ran with debug = 1). No data is
	  going to the tensorboard.
	* Started a thread on Ray Discuss at https://discuss.ray.io/t/tune-hangs-soon-after-starting/12081
	  to get help.

9/8/23

* Found defect in environment reset() method that induced an infinite loop occasionally, when trying to 
  place all of the neighbor vehicles within a close space. Fix allows training to move forward.
* Fixed defect in obs collection when neighbor was barely inside the front edge of the grid.

* Training run d226a using SAC on 2 trials. Reward function is scaled by 0.1 from what was used in
  cda0, so the reward range is now -1.5 for a crash, but otherwise within [-1, 1].
	* No good. rmax stayed < -1 for 3.5M steps (12k iterations).

9/16/23

* Run ? training with SAC
	* To accommodate changed reward scale, I added initial_alpha as a tuning HP.
	* Increased range of noise magnitude to [0.1, 0.4]
	* Added noise scale timesteps as a tunable HP to stretch it out more.
	* Extended trial duration from 12k iterations to 30k since it will probably take a lot longer for the agent
	  to experience all this track has to offer.
	* First 2 trials didn't do anything; rmax <= -1.
		* I discovered a defect in reading configs, such that it was not ignoring neighbor crashes, thus 
		  even if the agent was performing well, the episode may end with a poor reward.

* Run 5e343 training with SAC
	* Fixed config defects for setting boolean flags, correctly setting ignore_neighbor_crashes = True.
	* Changed max_iters back to 18k, since 30k took > 8 hr for two trials.
	* Adjusted reward penalty for speed deviation - multiplier from 0.03 to 0.015, since one inference example
	  (of prev run) showed that agent successfully stayed behind a bot at 14 m/s and got severely punished for
	  that, worse than if it had crashed.
	* Added a staging area from which to execute the training sessions, and a train.sh script to set it up and
	  initiate each run. This allows code editing & testing in the source area while running, without need to
	  make a second copy of the repo.
	* Inference on early trial (1) shows
		* Lots of crashes right after starting - it seems vehicles are packed too tightly together given the
		  wide range of start speeds.
	* Found a defect in VehicleModel, where it needs to have previous time step's obs passed in so that historical
	  reference info can be saved.

* Run a2caf training with SAC
	* Fixed defect that omitted proper updates of common obs vector elements.
	* Increased safe separation for initial vehicle placement from 4 to 5 car lengths.
	* Increased initial speed assignments from [0, MAX_SPEED] to [5, MAX_SPEED].
	* Added _decide_num_vehicles() to allow fewer vehicles to be present, especially during early episodes.


TODO:
- Build BridgitCtrl to read a checkpoint & execute it (preferably without Ray)
- Try running inference with real checkpoint - modify the action loop to use BridgitCtrl instead of loading directly?
- Investigate speed overshoot when speed limit changes (with bot1a controller)
- Review all TODOs
- Fix requirements.txt to either be pip compatible (to use pip install -r requirements.txt) or to be a conda import compatible.
- add bot1 lane change capability when on a ramp.
- find a way to load just the NN weights in inference (or in a vehicle controller) so that it can be run
  only with torch, no ray involved.

- Add lane IDs to graphics
- Add vehicle icons to graphics
- Allow env ctor to be called with an initialization code. 
	- value lane_exercise -> cycles reset() through 6 episodes, and each episode places a single vehicle at the
	  beginning of each lane, in sequence, and lets it run the entire lane. Use this to verify the basic functions
	  of the env, roadway, and graphics all work correctly.
- Add ego sensor display to graphics showing pvmt type/speed colors, vehicle speeds
